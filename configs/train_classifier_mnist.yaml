# This is a configuration file for training a classifier on the MNIST dataset.
data_dir : "D:/PycharmProjects/CF-Robustness-Benchmark/data"

# configure the dataset 
data: {
  class_name : 'MNISTDataset',
  name : "mnist",
  classes: [1, 7],
  num_classes: 2,
  img_size: 28,
  download: True,
  undersample_flag: False, # if the dataset is unbalanced, set to True to undersample the majority class in binary setting
  channels_first: True, # if True, the input tensor is in (C, H, W) format, otherwise (H, W, C)
  increase_channels: False # increase channels to 3 
}

epochs: 10
batch_size: 64

classifier:
  name: "SimpleCNNtorch" # a class name of the predictive model to use
  args:
    input_channels: 1 # number of input channels
    in_conv_channels: [1, 8, 16] 
    out_conv_channels: [8, 16, 32]
    conv_kernels: [7, 5, 3]
    softmax_flag: True
  # path to the checkpoints
  checkpoints_path: "D:/PycharmProjects/CF-Robustness-Benchmark/notebooks/experiments/mnist_classification/binary/checkpoints/mnist_1_8_epoch=08_val_loss=0.00.pth"

loss: 
  name: "CrossEntropyLoss" # loss function to use
  args: {}

optimizer:
  name: "Adam"
  args:
    lr: 0.001
    weight_decay: 0.0001

num_workers: 1
accelerator: "cpu"
devices: 1 # number of devices to use
save_dir: " "
checkpoint_path: " " # path to the checkpoint to resume training



