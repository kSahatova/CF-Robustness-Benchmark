{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 17:49:50.605004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747324190.623713  890352 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747324190.629524  890352 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747324190.645269  890352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747324190.645289  890352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747324190.645291  890352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747324190.645293  890352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-15 17:49:50.649951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.datasets import DatasetBuilder\n",
    "from src.utils import seed_everything, get_config, load_model_weights, evaluate_classification_model\n",
    "from src.cf_methods.coin import CounterfactualCGAN, CounterfactualTrainer\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare cuda to make a snapshot of the allocated memory  \n",
    "torch.cuda.memory._record_memory_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = '/data/leuven/365/vsc36567/CF-Robustness-Benchmark/configs' #'D:\\PycharmProjects\\CF-Robustness-Benchmark\\configs' #\n",
    "config_path = osp.join(config_dir, 'coin_derma.yaml')\n",
    "config = get_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_builder = DatasetBuilder(config)\n",
    "ds_builder.setup()\n",
    "train_loader, val_loader, test_loader = ds_builder.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# n_samples = 2\n",
    "# class_names = ds_builder.class_encodings\n",
    "# fig, axs = plt.subplots(1, n_samples, figsize=(10, 6))\n",
    "\n",
    "# batch = next(iter(train_loader))\n",
    "# images = batch[0][:n_samples]\n",
    "# labels = batch[1][:n_samples]\n",
    "\n",
    "# for i in range(n_samples):\n",
    "#     axs[i].imshow(images[i, ...].permute(1, 2, 0))\n",
    "#     axs[i].set_title(class_names[labels[i].item()], fontdict={'fontsize': 8})\n",
    "#     axs[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model and trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training of the COIN that uses a CF-CGAN, we need the model itself and the corresponding trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNConv in generator: False\n",
      "Generator in channels [1024, 1536, 768, 384, 192]\n",
      "Generator out channels [1024, 512, 256, 128, 64]\n",
      "Using SNConv in generator: False\n",
      "Using perturbation fuse scheme: skip_add_tanh\n"
     ]
    }
   ],
   "source": [
    "cfcgan = CounterfactualCGAN(opt=config, img_size=config.data.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 96166150\n",
      "Total size (parameters + buffers): 367.14 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_memory_usage(model: torch.nn.Module):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    param_size_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size_bytes = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    total_size_bytes = param_size_bytes + buffer_size_bytes\n",
    "    total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    print(f\"Total size (parameters + buffers): {total_size_mb:.2f} MB\")\n",
    "\n",
    "# Example usage\n",
    "get_model_memory_usage(cfcgan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 277.27 MB\n",
      "Reserved:  384.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Allocated: {torch.cuda.memory_allocated() / (1024**2):.2f} MB\")\n",
    "print(f\"Reserved:  {torch.cuda.memory_reserved() / (1024**2):.2f} MB\")\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch takes ~9.19 MB\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(16, 3, 224, 224)  # shape = (16, 3, 224, 224)\n",
    "input_bytes = input.numel() * input.element_size()\n",
    "input_MB = input_bytes / (1024**2)\n",
    "print(f\"Input batch takes ~{input_MB:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-15 17:53:41|INFO] - ================ Session (Thu May 15 17:53:41 2025) ================\n",
      "[2025-05-15 17:53:41|INFO] - Logging directory: /data/leuven/365/vsc36567/CF-Robustness-Benchmark/cf_output/derma/coin_cfe-May-15-2025_05+53PM-exp\n"
     ]
    }
   ],
   "source": [
    "trainer = CounterfactualTrainer(opt=config, model=cfcgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-15 17:58:28|INFO] - [Finished training epoch 0/10] [Epoch D loss: 1.635825] [Epoch G loss: 5.167821]             \n",
      "[2025-05-15 17:58:31|INFO] - [Average positives/negatives ratio in batch: 0.333000]\n",
      "[2025-05-15 17:58:31|INFO] - [Finished validation epoch 0/10] [Epoch D loss: 1.246488] [Epoch G loss: 0.940181]\n",
      "[2025-05-15 17:58:35|INFO] - Saved checkpoint parameters at epoch 0: /data/leuven/365/vsc36567/CF-Robustness-Benchmark/cf_output/derma/coin_cfe-May-15-2025_05+53PM-exp/checkpoints/checkpoint_0.pth\n",
      "[2025-05-15 18:03:19|INFO] - [Finished training epoch 1/10] [Epoch D loss: 0.849571] [Epoch G loss: 1.834591]             \n",
      "[2025-05-15 18:03:23|INFO] - [Average positives/negatives ratio in batch: 0.333000]\n",
      "[2025-05-15 18:03:23|INFO] - [Finished validation epoch 1/10] [Epoch D loss: 0.667349] [Epoch G loss: 1.447717]\n",
      "[2025-05-15 18:03:26|INFO] - Saved checkpoint parameters at epoch 1: /data/leuven/365/vsc36567/CF-Robustness-Benchmark/cf_output/derma/coin_cfe-May-15-2025_05+53PM-exp/checkpoints/checkpoint_1.pth\n",
      "[2025-05-15 18:08:10|INFO] - [Finished training epoch 2/10] [Epoch D loss: 0.927399] [Epoch G loss: 2.256179]             \n",
      "[2025-05-15 18:08:14|INFO] - [Average positives/negatives ratio in batch: 0.333000]\n",
      "[2025-05-15 18:08:14|INFO] - [Finished validation epoch 2/10] [Epoch D loss: 0.722208] [Epoch G loss: 1.149604]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit([train_loader, val_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._dump_snapshot(\"my_snapshot.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 15 16:28:55 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-SXM2-16GB           Off |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   34C    P0             42W /  300W |   16267MiB /  16384MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    823663      C   .../365/vsc36567/miniconda3/bin/python      16264MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16694027776"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1481.81s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 15 16:42:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-SXM2-16GB           Off |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             42W /  300W |   16257MiB /  16384MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    823663      C   .../365/vsc36567/miniconda3/bin/python      16254MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
