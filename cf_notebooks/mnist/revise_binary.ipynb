{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d037efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.datasets import DatasetBuilder\n",
    "from src.models.classifiers import SimpleCNNtorch\n",
    "from src.models.vae import BetaVAE\n",
    "from src.cf_methods import Revise\n",
    "from src.evaluation.local_instability import perturb_sample\n",
    "from src.utils.generic_utils import extract_factual_instances, filter_tp_instances\n",
    "from src.utils.generic_utils import seed_everything, get_config, load_model_weights\n",
    "from src.utils.generic_utils import evaluate_classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d9f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3019140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = r\"D:\\PycharmProjects\\CF-Robustness-Benchmark\\configs\\revise_mnist_binary.yaml\"\n",
    "config = get_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b394649",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_builder = DatasetBuilder(config)\n",
    "ds_builder.setup()\n",
    "train_loader, val_loader, test_loader = ds_builder.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c8b1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.save_dir, exist_ok=True)\n",
    "class_names = ds_builder.class_encodings\n",
    "classes4fname = (\"_\").join([str(i) for i in class_names.values()]) if config.data.num_classes == 2 else \"\"\n",
    "ds_name = config.data.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871437d",
   "metadata": {},
   "source": [
    "### Load the classifier and VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "978e66b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the test dataset: 99.265%\n"
     ]
    }
   ],
   "source": [
    "baseline_classifier = SimpleCNNtorch(**config.classifier.args,\n",
    "                                     img_size=config.data.img_size)\n",
    "load_model_weights(baseline_classifier, weights_path=config.classifier.checkpoints_path)\n",
    "evaluate_classification_model(baseline_classifier, test_loader, config.data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718fd699",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = BetaVAE(**config.vae.args, input_size=(config.data.img_size, config.data.img_size))\n",
    "load_model_weights(vae, weights_path=config.vae.checkpoints_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09cdeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = config.accelerator\n",
    "vae = vae.to(device)\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    images, _ = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "\n",
    "    z, _ = vae.encoder(images)\n",
    "    recon_images = vae.decoder(z)\n",
    "    recon_images = recon_images.to(device)\n",
    "\n",
    "    # plot reconstructed images\n",
    "    _, axes = plt.subplots(2, 8, figsize=(15, 4))\n",
    "    for i in range(8):\n",
    "        axes[0, i].imshow(images[i].permute(1, 2, 0).cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(recon_images[i].permute(1, 2, 0).cpu().squeeze(), cmap='gray')\n",
    "        axes[1, i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479603ff",
   "metadata": {},
   "source": [
    "### Preparing factual test instances and their perturbed versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a48ec5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "factuals, labels = extract_factual_instances(test_loader, init_class_idx=0)\n",
    "factuals, labels = filter_tp_instances(factuals, labels, baseline_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08ee3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "# Checking for correctly predicted factuals \n",
    "preds = torch.argmax(baseline_classifier(factuals), axis=1)\n",
    "print('Accuracy: {:.0%}'.format(torch.where(preds == labels)[0].shape[0] / factuals.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e8d9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_magnitudes = [0.001, 0.0025, 0.005, 0.0075, 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a284f",
   "metadata": {},
   "source": [
    "Prepare perturbed factual instances for the generation of CFEs. We need those perturbed factuals that\n",
    "are predicted correctly by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f7d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid perturbed factuals for the added noise level 0.001:  1132\n",
      "Number of valid perturbed factuals for the added noise level 0.0025:  1132\n",
      "Number of valid perturbed factuals for the added noise level 0.005:  1132\n",
      "Number of valid perturbed factuals for the added noise level 0.0075:  1132\n",
      "Number of valid perturbed factuals for the added noise level 0.01:  1132\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "factuals_pert = {}\n",
    "indices_pert = {}\n",
    "\n",
    "for noise in noise_magnitudes:\n",
    "    pert_sample = perturb_sample(factuals, n_samples=1, noise_magnitude=noise)\n",
    "    pert_sample = torch.Tensor(pert_sample)\n",
    "\n",
    "    # Check whether perturbed instances lead to the same class prediction\n",
    "    predictions = torch.argmax(baseline_classifier(pert_sample), axis=1).detach().cpu()\n",
    "    indices = np.where(predictions == labels)[0]\n",
    "    print(f'Number of valid perturbed factuals for the added noise level {noise}: ', indices.shape[0])\n",
    "    factuals_pert[noise] = pert_sample\n",
    "    indices_pert[noise] = indices\n",
    "\n",
    "final_indices = reduce(np.intersect1d, list(indices_pert.values()))\n",
    "factuals_pert = {k : v[final_indices][:n] for k, v in factuals_pert.items()}\n",
    "factuals = factuals[final_indices][:n]\n",
    "labels = labels[final_indices][:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6b476",
   "metadata": {},
   "source": [
    "Visualize the factual instances perturbed with different noise magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f124b049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 10\n",
    "n_rows = 1\n",
    "n_cols = len(noise_magnitudes) + 1\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(10, 4))\n",
    "\n",
    "for j in range(n_cols):\n",
    "    if j == 0: \n",
    "        axs[j].imshow(factuals[ind].squeeze().squeeze(), cmap='gray')\n",
    "        axs[j].set_title('$\\\\epsilon$=0') \n",
    "        axs[j].axis('off')\n",
    "    else:\n",
    "        noise = noise_magnitudes[j-1]\n",
    "        pert_image = factuals_pert[noise][ind].squeeze().squeeze() \n",
    "        axs[j].imshow(pert_image, cmap='gray')\n",
    "        axs[j].set_title('$\\\\epsilon$='+str(noise)) \n",
    "        axs[j].axis('off')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7c4fa",
   "metadata": {},
   "source": [
    "# Generate CFEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "015a1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = config.revise_hyperparameters\n",
    "revise_method = Revise(baseline_classifier, vae, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc1b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:34<57:41, 34.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterfactual found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:45<1:15:18, 45.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrevise_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_counterfactuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactuals\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pycharmprojects\\cf-robustness-benchmark\\src\\cf_methods\\revise\\model.py:93\u001b[0m, in \u001b[0;36mget_counterfactuals\u001b[1;34m(self, factuals, verbose)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae \u001b[38;5;241m=\u001b[39m vae\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_counterfactuals\u001b[39m(\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m, factuals: torch\u001b[38;5;241m.\u001b[39mTensor, verbose: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     95\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counterfactual_optimization(factuals, verbose)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_counterfactual_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, factuals: torch\u001b[38;5;241m.\u001b[39mTensor, verbose: \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32md:\\pycharmprojects\\cf-robustness-benchmark\\src\\cf_methods\\revise\\model.py:124\u001b[0m, in \u001b[0;36m_counterfactual_optimization\u001b[1;34m(self, factuals, verbose)\u001b[0m\n\u001b[0;32m    121\u001b[0m     optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mRMSprop([z], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lr)\n\u001b[0;32m    123\u001b[0m candidate_counterfactuals \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# all possible counterfactuals\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m candidate_distances \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    125\u001b[0m all_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter):\n",
      "File \u001b[1;32md:\\pycharmprojects\\cf-robustness-benchmark\\src\\models\\vae.py:252\u001b[0m, in \u001b[0;36mBetaVAE.decoder\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m    248\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_input(z)\n\u001b[0;32m    249\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mview(\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dims[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    251\u001b[0m )\n\u001b[1;32m--> 252\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(result)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfes = revise_method.get_counterfactuals(factuals, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 2/100 [00:18<14:54,  9.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m cfes_pert \u001b[38;5;241m=\u001b[39m {} \n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m noise \u001b[38;5;129;01min\u001b[39;00m noise_magnitudes:\n\u001b[1;32m---> 11\u001b[0m     cfes_list \u001b[38;5;241m=\u001b[39m \u001b[43mrevise_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_counterfactuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactuals_pert\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     cfes_pert[noise] \u001b[38;5;241m=\u001b[39m cfes_list\n\u001b[0;32m     14\u001b[0m     fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcfes_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses4fname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_noise_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32md:\\pycharmprojects\\cf-robustness-benchmark\\src\\cf_methods\\revise\\model.py:96\u001b[0m, in \u001b[0;36mRevise.get_counterfactuals\u001b[1;34m(self, factuals, verbose)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_counterfactuals\u001b[39m(\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m, factuals: torch\u001b[38;5;241m.\u001b[39mTensor, verbose: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     95\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_counterfactual_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\pycharmprojects\\cf-robustness-benchmark\\src\\cf_methods\\revise\\model.py:143\u001b[0m, in \u001b[0;36mRevise._counterfactual_optimization\u001b[1;34m(self, factuals, verbose)\u001b[0m\n\u001b[0;32m    138\u001b[0m     candidate_counterfactuals\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    139\u001b[0m         cf\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    141\u001b[0m     candidate_distances\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m--> 143\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    145\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\CF-Robustness-Benchmark\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfes_pert = {} \n",
    "\n",
    "for noise in noise_magnitudes:\n",
    "    cfes_pert[noise] = revise_method.get_counterfactuals(factuals_pert[noise], verbose=False)\n",
    "     \n",
    "    fname = f'cfes_{ds_name.lower()}_{classes4fname}_noise_{noise}.pkl'\n",
    "    with open(osp.join(config.save_dir, fname), 'wb') as f:\n",
    "        pickle.dump(cfes_pert[noise], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111499c",
   "metadata": {},
   "source": [
    "## Local Instability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452fbdd",
   "metadata": {},
   "source": [
    "Checking validity of explanations after perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cls_ind = 1\n",
    "\n",
    "validity_dict = {}\n",
    "for noise in noise_magnitudes:\n",
    "    predictions = torch.argmax(baseline_classifier(torch.Tensor(cfes_pert[noise])), axis=1).detach().cpu()\n",
    "    indices = np.where(predictions == torch.ones_like(predictions)*target_cls_ind)[0]\n",
    "    validity = indices.shape[0] / predictions.shape[0]\n",
    "    validity_dict[noise] = validity\n",
    "    print(f'Validity for the added noise level {noise}: ',  validity)\n",
    "\n",
    "fname = f'revise_{ds_name.lower()}_{classes4fname}_validity.pkl'\n",
    "with open(osp.join(config.save_dir, fname), 'wb') as f:\n",
    "    pickle.dump(validity_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.local_instability import calculate_sparsity, calculate_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instability_l1_list = []\n",
    "ssim_list = []\n",
    "\n",
    "for noise, cfe_pert_list in cfes_pert.items():\n",
    "    l1_temp = []\n",
    "    ssim_temp = []\n",
    "    for i in range(len(cfes)):\n",
    "        cf = cfes[i]\n",
    "        cf_pert = cfe_pert_list[i]\n",
    "\n",
    "        if len(cf) != 0 and len(cf_pert) != 0:\n",
    "\n",
    "            cf_tensor = torch.Tensor(cf)\n",
    "            cf = cf_tensor.permute(1, 2, 0).flatten()\n",
    "\n",
    "            cf_pert_tensor = torch.Tensor(cf_pert)\n",
    "            cf_perturbed = cf_pert_tensor.permute(1, 2, 0).flatten()        \n",
    "\n",
    "            l1_distance = sum(abs(cf - cf_perturbed)) # np.linalg.norm(cf.flatten() - cf_perturbed.flatten(), ord=1)\n",
    "            l1_temp.append(l1_distance)\n",
    "\n",
    "            ssim = calculate_ssim(cf_tensor.unsqueeze(0), cf_pert_tensor.unsqueeze(0)).item()\n",
    "            ssim_temp.append(ssim)\n",
    "\n",
    "    instability_l1_list.append(l1_temp)\n",
    "    ssim_list.append(ssim_temp)\n",
    "\n",
    "with open(osp.join(config.save_dir, f'revise_{ds_name.lower()}_{classes4fname}_li_l1_.pkl'), 'wb') as f:\n",
    "    pickle.dump(instability_l1_list, f)\n",
    "\n",
    "with open(osp.join(config.save_dir, f'revise_{ds_name.lower()}_{classes4fname}_ssim.pkl'), 'wb') as f:\n",
    "    pickle.dump(ssim_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d6b4e",
   "metadata": {},
   "source": [
    "## Local Lipschitz Continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_points = factuals\n",
    "original_cfes = cfes\n",
    "print(\"Are the lengths of initial points (factuals) and CFEs generated for them equal :\", len(original_cfes) == original_points.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_magnitude = 0.001\n",
    "n_samples = 30\n",
    "revise_method._params[\"max_iter\"] = 400\n",
    "\n",
    "lip_estimates = []\n",
    "\n",
    "i = 0\n",
    "for original_point, original_cfe in tqdm(zip(original_points[:n_samples], original_cfes[:n_samples])):\n",
    "\n",
    "    neighbor_points = perturb_sample(original_point.unsqueeze(0), \n",
    "                                     n_samples=30, \n",
    "                                     noise_magnitude=noise_magnitude)    \n",
    "    neighbor_points = torch.Tensor(neighbor_points)\n",
    "    neighbor_cfes = revise_method.get_counterfactuals(neighbor_points, verbose=False)\n",
    "\n",
    "    lip_estimate = 0\n",
    "    for m, p in tqdm(zip(neighbor_cfes, neighbor_points)):\n",
    "        if not isinstance(m, list):\n",
    "            num = np.linalg.norm((original_cfe - m).flatten(), ord=2) \n",
    "            denom = np.linalg.norm((original_point - p).flatten(), ord=2)\n",
    "            lip = num / denom\n",
    "            lip_estimate = max(lip, lip_estimate)\n",
    " \n",
    "    lip_estimates.append(lip_estimate)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(config.save_dir, f'revise_{ds_name.lower()}_{classes4fname}_lle.pkl'), 'wb') as f:\n",
    "        pickle.dump(lip_estimates, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04652e5",
   "metadata": {},
   "source": [
    "## Invalidation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48bfca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the test dataset: 99.632%\n",
      "Accuracy for the test dataset: 99.173%\n",
      "Accuracy for the test dataset: 99.311%\n",
      "Accuracy for the test dataset: 99.403%\n",
      "Accuracy for the test dataset: 99.311%\n",
      "Accuracy for the test dataset: 99.540%\n",
      "Accuracy for the test dataset: 99.311%\n",
      "Accuracy for the test dataset: 99.494%\n",
      "Accuracy for the test dataset: 99.586%\n",
      "Accuracy for the test dataset: 99.449%\n"
     ]
    }
   ],
   "source": [
    "classifiers_weights_dir = r'D:\\PycharmProjects\\CF-Robustness-Benchmark\\notebooks\\experiments\\mnist_classification\\binary\\checkpoints\\mc_1_7'\n",
    "\n",
    "\n",
    "classifiers_list = []\n",
    "for clf_weights in os.listdir(classifiers_weights_dir):\n",
    "    cnn_perturbed = SimpleCNNtorch(**config.classifier.args,\n",
    "                                     img_size=config.data.img_size)\n",
    "    load_model_weights(model=cnn_perturbed, \n",
    "                       weights_path=osp.join(classifiers_weights_dir, clf_weights))\n",
    "    classifiers_list.append(cnn_perturbed)\n",
    "    evaluate_classification_model(cnn_perturbed, \n",
    "                                  dataloader=test_loader, \n",
    "                                  num_classes=config.data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 1\n",
    "validity_list = []\n",
    "invalidation_rate_list = []\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "for i, classifier in enumerate(classifiers_list):\n",
    "    validity = 0\n",
    "    invalidation_rate = 0\n",
    "    total_found_cfs = 0\n",
    "    \n",
    "    for cfe in cfes:\n",
    "        if isinstance(cfe, list):\n",
    "            continue\n",
    "        \n",
    "        cfe = torch.Tensor(cfe).unsqueeze(0).to(device)\n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            classifier = classifier.to(device)\n",
    "\n",
    "            baseline_pred = torch.argmax(baseline_classifier(cfe), axis=1)\n",
    "            alternative_pred = torch.argmax(classifier(cfe), axis=1)\n",
    "\n",
    "        total_found_cfs += 1\n",
    "\n",
    "        if baseline_pred != alternative_pred:\n",
    "            invalidation_rate += 1\n",
    "\n",
    "        if alternative_pred == target_class:\n",
    "                validity += 1\n",
    "\n",
    "    invalidation_rate /= total_found_cfs\n",
    "    invalidation_rate_list.append(invalidation_rate)\n",
    "    validity_list.append(validity / total_found_cfs)\n",
    "    print(f'Model {i}: IR={invalidation_rate}, validity={validity}\\n')\n",
    "\n",
    "print(f'Average IR among {len(classifiers_list)} models: ', np.mean(invalidation_rate_list), '+-', np.std(invalidation_rate_list))\n",
    "print(f'Average VaR among {len(classifiers_list)} models: ', np.mean(validity_list), '+-', np.std(validity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c6f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45aa7afc",
   "metadata": {},
   "source": [
    "## Relaxed Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90105fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000\n",
    "sigma = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "average_stability_list = []\n",
    "for i, classifier in enumerate(classifiers_list):\n",
    "    stability_list = []\n",
    "    for cfe in cfes:\n",
    "        if isinstance(cfe, list):\n",
    "            continue\n",
    "\n",
    "        cfe = torch.Tensor(cfe).unsqueeze(0)\n",
    "        cfe_sampled = torch.Tensor(perturb_sample(cfe, n_samples=k, noise_magnitude=sigma))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            cf_logits = classifier(cfe.to(device))\n",
    "            cf_probabilities = F.softmax(cf_logits, dim=-1)[:, target_class]\n",
    "\n",
    "            cf_sampled_logits = classifier(cfe_sampled.to(device))\n",
    "            cf_sampled_probabilities = F.softmax(cf_sampled_logits, dim=-1)[:, target_class]\n",
    "        \n",
    "        model_variance = abs(cf_probabilities - cf_sampled_probabilities)\n",
    "\n",
    "        stability = (cf_sampled_probabilities - model_variance).mean()\n",
    "        stability_list.append(stability.item())\n",
    "\n",
    "    avg_i_stability = np.mean(stability_list)\n",
    "    print(f'Stability of the model {i}: {round(avg_i_stability.item(), 3)} +- {round(np.std(stability_list).item(), 2)}')\n",
    "    average_stability_list.append(avg_i_stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average stability over {len(classifiers_list)} models:', np.mean(average_stability_list).round(4), '+-', +- np.std(average_stability_list).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cfc8fe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
